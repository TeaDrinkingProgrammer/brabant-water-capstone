{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp        0\n",
      "precipitation    0\n",
      "percentage       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:05:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:10:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:20:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507883</th>\n",
       "      <td>2023-11-10 00:40:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507884</th>\n",
       "      <td>2023-11-10 00:45:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507885</th>\n",
       "      <td>2023-11-10 00:50:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507886</th>\n",
       "      <td>2023-11-10 00:55:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507887</th>\n",
       "      <td>2023-11-10 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>507888 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp  precipitation  percentage\n",
       "0      2019-01-01 00:00:00            0.0       7.895\n",
       "1      2019-01-01 00:05:00            0.0       7.895\n",
       "2      2019-01-01 00:10:00            0.0       7.895\n",
       "3      2019-01-01 00:15:00            0.0       7.895\n",
       "4      2019-01-01 00:20:00            0.0       7.895\n",
       "...                    ...            ...         ...\n",
       "507883 2023-11-10 00:40:00            0.0       0.814\n",
       "507884 2023-11-10 00:45:00            0.0       1.106\n",
       "507885 2023-11-10 00:50:00            0.0       1.399\n",
       "507886 2023-11-10 00:55:00            0.0       1.692\n",
       "507887 2023-11-10 01:00:00            0.0       1.985\n",
       "\n",
       "[507888 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data/cleaned_data/merged_df.parquet and put it into variable merged_df\n",
    "import pandas as pd\n",
    "\n",
    "merged_df = pd.read_parquet('data/cleaned_data/merged_df.parquet')\n",
    "\n",
    "# check if merged_df has nan values\n",
    "print(merged_df.isna().sum())\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from datetime import datetime\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datimetime to seperate features\n",
    "import datetime as dt\n",
    "\n",
    "def convert_timestamp_to_numerical(dataset):\n",
    "    dataset = dataset.copy()\n",
    "    dataset['day'] = dataset['timestamp'].dt.day\n",
    "    dataset['month'] = dataset['timestamp'].dt.month\n",
    "    # dataset['year'] = dataset['timestamp'].dt.year\n",
    "    dataset['dayofweek'] = dataset['timestamp'].dt.dayofweek\n",
    "    dataset['hour'] = dataset['timestamp'].dt.hour\n",
    "    # dataset['date'] = pd.to_datetime(dataset['timestamp'])\n",
    "    # dataset['date'] = dataset['date'].map(dt.datetime.toordinal)\n",
    "    # dataset['minute'] = dataset['timestamp'].dt.minute\n",
    "\n",
    "    # in dataset, timestamp is the first column. put day, month, dayofweek, hour behind timestamp\n",
    "    cols = dataset.columns.tolist()\n",
    "    cols = cols[0:1] + cols[-4:] + cols[1:-4]\n",
    "    dataset = dataset[cols]\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timestamp_for_testing = pd.to_datetime('2023-03-06 08:00:00')\n",
    "end_timestamp_for_testing = pd.to_datetime('2023-03-20 08:00:00')\n",
    "# start_timestamp_for_testing = pd.to_datetime('2023-03-01 08:00:00')\n",
    "# end_timestamp_for_testing = pd.to_datetime('2023-03-31 08:00:00')\n",
    "# start_timestamp_for_testing = pd.to_datetime('2023-10-01 08:00:00')\n",
    "# end_timestamp_for_testing = pd.to_datetime('2023-10-31 08:00:00')\n",
    "\n",
    "def get_datasets_and_scaler(merged_df, features):\n",
    "   #  Define the features and target variables to be used\n",
    "   X = merged_df[features]\n",
    "   y = merged_df['percentage_current']\n",
    "\n",
    "   # scale the features\n",
    "   scaler = StandardScaler()\n",
    "   scaler.fit(X)\n",
    "   \n",
    "   # for testing specific dates\n",
    "   X_test_specific = merged_df[(merged_df['timestamp'] >= start_timestamp_for_testing) & (merged_df['timestamp'] <= end_timestamp_for_testing)][features]\n",
    "   X_test_specific = scaler.transform(X_test_specific)\n",
    "   y_test_specific = merged_df[(merged_df['timestamp'] >= start_timestamp_for_testing) & (merged_df['timestamp'] <= end_timestamp_for_testing)]['percentage_current']\n",
    "   \n",
    "   X = scaler.transform(X)\n",
    "\n",
    "   # Create the training and test sets\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=41, shuffle=True)\n",
    "\n",
    "   return X_train, X_test, y_train, y_test, scaler, X_test_specific, y_test_specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test, y_test, predictions):\n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    accuracy = round(accuracy * 100, 2)\n",
    "    print(f\"Accuracy: {accuracy}%\")\n",
    "\n",
    "    # Calculate the mean squared error of the model\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    print(f\"Mean squared error: {mse}\")\n",
    "\n",
    "    # Calculate the R-Squared score of the model\n",
    "    print('Variance (R²) score: %.2f' % r2_score(y_test, predictions))\n",
    "\n",
    "def save_to_pickle_file(file, filename):\n",
    "    pickle.dump(file, open(filename, 'wb'))\n",
    "\n",
    "def plot_predicted_vs_actual(y_test, predictions):\n",
    "    # Plot the predictions against the actual values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, predictions)\n",
    "    plt.xlabel('Actual percentage')\n",
    "    plt.ylabel('Predicted percentage')\n",
    "    plt.title('Predicted percentage vs. Actual percentage')\n",
    "    plt.show()\n",
    "\n",
    "def print_time_taken(start_time, end_time):\n",
    "    print(f\"Time taken: {time.strftime('%H:%M:%S', time.gmtime(end_time - start_time))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['day',\n",
       " 'month',\n",
       " 'dayofweek',\n",
       " 'hour',\n",
       " 'rainfall_current',\n",
       " 'rainfall_previous_2_hours',\n",
       " 'percentage_previous_1',\n",
       " 'percentage_previous_2',\n",
       " 'percentage_previous_3',\n",
       " 'percentage_previous_4',\n",
       " 'percentage_previous_5',\n",
       " 'percentage_previous_6']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model = True\n",
    "calibrate_lag_features = False\n",
    "\n",
    "linear_model = False\n",
    "ridge_model = False\n",
    "lasso_model = False\n",
    "elastic_net_model = False\n",
    "linear_optuna_model = True\n",
    "polynomial_model = False\n",
    "random_forest_model = False\n",
    "sarimix_model = False\n",
    "\n",
    "# features = ['percentage_previous_1', 'percentage_previous_2', 'percentage_previous_3']\n",
    "date_features = ['day', 'month', 'dayofweek', 'hour']\n",
    "rainfall_features = ['rainfall_current', 'rainfall_previous_2_hours']\n",
    "rainfall_previous_features = ['rainfall_previous_1', 'rainfall_previous_2', 'rainfall_previous_3', 'rainfall_previous_4', 'rainfall_previous_5', 'rainfall_previous_6'] \n",
    "percentage_previous_features = ['percentage_previous_1', 'percentage_previous_2', 'percentage_previous_3', 'percentage_previous_4', 'percentage_previous_5', 'percentage_previous_6']\n",
    "percentage_difference_features = ['percentage_difference_1', 'percentage_difference_2', 'percentage_difference_3', 'percentage_difference_4', 'percentage_difference_5', 'percentage_difference_6', 'percentage_difference_7', 'percentage_difference_8', 'percentage_difference_9', 'percentage_difference_10', 'percentage_difference_11', 'percentage_difference_12']\n",
    "# put the values in above arrays in one array\n",
    "\n",
    "if(calibrate_lag_features):\n",
    "    features = date_features + rainfall_features\n",
    "else:\n",
    "    features = date_features + rainfall_features + percentage_previous_features\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there null values? False\n",
      "timestamp                    datetime64[ns]\n",
      "day                                   int32\n",
      "month                                 int32\n",
      "dayofweek                             int32\n",
      "hour                                  int32\n",
      "rainfall_current                    float64\n",
      "percentage_current                  float64\n",
      "rainfall_previous_2_hours           float64\n",
      "percentage_previous_1               float64\n",
      "percentage_previous_2               float64\n",
      "percentage_previous_3               float64\n",
      "percentage_previous_4               float64\n",
      "percentage_previous_5               float64\n",
      "percentage_previous_6               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# adjust columns\n",
    "\n",
    "# rename columns\n",
    "merged_df.rename(columns={'precipitation': 'rainfall_current'}, inplace=True)\n",
    "merged_df.rename(columns={'percentage': 'percentage_current'}, inplace=True)\n",
    "\n",
    "if(not calibrate_lag_features):\n",
    "    # sum up the rainfall_current of the previous 24 records and put it into a new column rainfall_previous_24\n",
    "    merged_df['rainfall_previous_2_hours'] = merged_df['rainfall_current'].rolling(25).sum() - merged_df['rainfall_current']\n",
    "    merged_df['rainfall_previous_2_hours'].fillna(0, inplace=True)\n",
    "\n",
    "    # the percentage of the previous 6 records in new columns\n",
    "    for shift_rate in range(1, 7):\n",
    "        merged_df[f'percentage_previous_{shift_rate}'] = merged_df['percentage_current'].shift(shift_rate)\n",
    "        merged_df[f'percentage_previous_{shift_rate}'].fillna(0, inplace=True)\n",
    "\n",
    "    # rainfall_lag_start = 12\n",
    "    # # now shift rainfall_current an use a for loop to create rainfall_previous_1 to rainfall_previous_6\n",
    "    # for shift_rate in range(1, 7):\n",
    "    #     merged_df[f'rainfall_previous_{shift_rate}'] = merged_df['rainfall_current'].shift(shift_rate + rainfall_lag_start)\n",
    "    #     merged_df[f'rainfall_previous_{shift_rate}'].fillna(0, inplace=True)\n",
    "            \n",
    "    # # the difference between the current percentage and the previous 6 percentage in new columns\n",
    "    # for shift_rate in range(1, 7):\n",
    "    #     merged_df[f'percentage_difference_{shift_rate}'] = merged_df['percentage_current'].shift(shift_rate) - merged_df['percentage_current'].shift(shift_rate + 1)\n",
    "    #     merged_df[f'percentage_difference_{shift_rate}'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "print('Are there null values?', merged_df.isnull().values.any())\n",
    "\n",
    "merged_df = convert_timestamp_to_numerical(merged_df)\n",
    "\n",
    "print(merged_df.dtypes)\n",
    "# merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not calibrate_lag_features):\n",
    "    X_train, X_test, y_train, y_test, scaler, X_test_specific, y_test_specific = get_datasets_and_scaler(merged_df, features)\n",
    "\n",
    "    if train_model:\n",
    "        # save scaler to folder models\\linear_regression, with a timestamp in the name\n",
    "        filename = 'scalers/scaler_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.pkl'\n",
    "        pickle.dump(scaler, open(filename, 'wb'))\n",
    "\n",
    "        def scale_features(features):\n",
    "            return scaler.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag features tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_lag_features:\n",
    "    # show minimal output\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "    rainfall_cumulative_calibration = True\n",
    "    percentage_previous_calibration = True\n",
    "\n",
    "    if rainfall_cumulative_calibration and not percentage_previous_calibration:\n",
    "        print(\"TUNING RAINFALL CUMULATIVE - Percentage previous filled\")\n",
    "        for shift_rate in range(1, 7):\n",
    "            merged_df[f'percentage_previous_{shift_rate}'] = merged_df['percentage_current'].shift(shift_rate)\n",
    "            merged_df[f'percentage_previous_{shift_rate}'].fillna(0, inplace=True)\n",
    "        \n",
    "        features = features + percentage_previous_features\n",
    "    elif percentage_previous_calibration and not rainfall_cumulative_calibration:\n",
    "        print(\"TUNING PERCENTAGE PREVIOUS - Rainfall cumulative filled\")\n",
    "        merged_df['rainfall_previous_2_hours'] = merged_df['rainfall_current'].rolling(26).sum() - merged_df['rainfall_current']\n",
    "        merged_df['rainfall_previous_2_hours'].fillna(0, inplace=True)\n",
    "\n",
    "    print(\"features:\", features)\n",
    "\n",
    "    def objective(trial):\n",
    "        merged_df_optuna = merged_df.copy()\n",
    "\n",
    "        # Rainfall cumulative tuning\n",
    "        if rainfall_cumulative_calibration:\n",
    "            shift_rainfall_cumulative = None\n",
    "            roll_rainfall_cumulative = None\n",
    "\n",
    "            # Everything in try block, suggestion can result as None and throw error\n",
    "            try:     \n",
    "                # Suggest hyperparameters\n",
    "                shift_rainfall_cumulative = trial.suggest_int('shift_rainfall_param', 0, 60)\n",
    "                roll_rainfall_cumulative = trial.suggest_int('roll_rainfall_param', 2, 60)\n",
    "            except Exception as e_1:\n",
    "                print(f\"Exception: {e_1}\")\n",
    "                if shift_rainfall_cumulative is None:\n",
    "                    print('-> shift is None')\n",
    "                    shift_rainfall_cumulative = 0\n",
    "                    try: \n",
    "                        roll_rainfall_cumulative = trial.suggest_int('roll_rainfall_param', 2, 60)\n",
    "                    except Exception as e_2:\n",
    "                        print(f\"Exception: {e_2}\")\n",
    "                        if roll_rainfall_cumulative is None:\n",
    "                            print('-> shift and roll are None')\n",
    "                            roll_rainfall_cumulative = 2\n",
    "                \n",
    "                if roll_rainfall_cumulative is None:\n",
    "                    print('-> roll is None')\n",
    "                    roll_rainfall_cumulative = 2\n",
    "        \n",
    "            # Apply suggested params to rainfall cumulative\n",
    "            start_record = merged_df_optuna['rainfall_current'].shift(shift_rainfall_cumulative)\n",
    "            \n",
    "            if start_record.isnull().values.any():\n",
    "                merged_df_optuna['rainfall_previous_2_hours'] = 0\n",
    "            else:\n",
    "                rollback_sum = start_record.rolling(roll_rainfall_cumulative).sum().fillna(0)\n",
    "                merged_df_optuna['rainfall_previous_2_hours'] = rollback_sum - start_record\n",
    "        \n",
    "            # merged_df_optuna['rainfall_previous_2_hours'].fillna(0, inplace=True)\n",
    "\n",
    "            if not percentage_previous_calibration:            \n",
    "                X_train, X_test, y_train, y_test, scaler, X_test_specific, y_test_specific = get_datasets_and_scaler(merged_df_optuna, features)\n",
    "\n",
    "        # Percentage previous tuning\n",
    "        if percentage_previous_calibration:\n",
    "            percentage_previous_features = []\n",
    "            try:     \n",
    "                # Suggest hyperparameters\n",
    "                shift_percentage_previous = trial.suggest_int('shift_percentage_param', 1, 60)\n",
    "                roll_percentage_previous = trial.suggest_int('roll_percentage_param', 1, 60)\n",
    "                # print(f\"shift_percentage_previous: {shift_percentage_previous} | roll_percentage_previous: {roll_percentage_previous}\")\n",
    "            except Exception as e_1:\n",
    "                print(f\"Exception: {e_1}\")\n",
    "                if shift_percentage_previous is None:\n",
    "                    print('-> shift percentage is None')\n",
    "                    shift_percentage_previous = 1\n",
    "                    try: \n",
    "                        roll_percentage_previous = trial.suggest_int('roll_percentage_param', 1, 60)\n",
    "                    except Exception as e_2:\n",
    "                        print(f\"Exception: {e_2}\")\n",
    "                        if roll_percentage_previous is None:\n",
    "                            print('-> shift and roll percentage are None')\n",
    "                            roll_percentage_previous = 1\n",
    "                \n",
    "                if roll_percentage_previous is None:\n",
    "                    print('-> roll is None')\n",
    "                    roll_percentage_previous = 1\n",
    "\n",
    "            # the percentage of the previous 6 records in new columns\n",
    "            for roll in range(1, roll_percentage_previous + 1):\n",
    "                previous_value = merged_df_optuna['percentage_current'].shift(shift_percentage_previous + roll - 1).fillna(0)   \n",
    "                merged_df_optuna[f'percentage_previous_{roll}'] = previous_value\n",
    "\n",
    "                # merged_df_optuna[f'percentage_previous_{roll}'].fillna(0, inplace=True)\n",
    "                percentage_previous_features.append(f'percentage_previous_{roll}')\n",
    "\n",
    "            X_train, X_test, y_train, y_test, scaler, X_test_specific, y_test_specific = get_datasets_and_scaler(merged_df_optuna, features + percentage_previous_features)\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "\n",
    "        # predictions = model.predict(X_test_specific)\n",
    "\n",
    "        # accuracy = model.score(X_test_specific, y_test)\n",
    "        # mse = mean_squared_error(y_test, predictions)\n",
    "        # r2 = r2_score(y_test, predictions)\n",
    "\n",
    "        # check if accuracy, mse or r2 is None, metric may result as None and will throw error\n",
    "        if accuracy is None or mse is None or r2 is None:\n",
    "            print('--------------------------------------------------------------------', accuracy, mse, r2)\n",
    "            if accuracy is None:\n",
    "                accuracy = 0\n",
    "            if mse is None:\n",
    "                mse = 9999999\n",
    "            if r2 is None:\n",
    "                r2 = 0\n",
    "\n",
    "        # return accuracy\n",
    "        return accuracy, mse, r2 # The objective to be maximized\n",
    "\n",
    "    # Initialize Optuna study\n",
    "    # study = optuna.create_study(direction=\"maximize\")\n",
    "    study = optuna.create_study(directions=[\"maximize\", \"minimize\", \"maximize\"])\n",
    "\n",
    "    # track time in hours and minutes\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Optimize the study, the objective function is called here\n",
    "    study.optimize(objective, n_trials=20000, n_jobs=120, show_progress_bar=True)  # Adjust n_trials for your needs\n",
    "\n",
    "    print_time_taken(start_time, time.time())\n",
    "\n",
    "    # Print the best parameters\n",
    "    for best_trial in study.best_trials:\n",
    "        print(f\"Best values: {best_trial.values} | best params: {best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------- START MODEL TRAINING --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use TPOT to find the best model\n",
    "# from tpot import TPOTRegressor\n",
    "\n",
    "# # Use TPOT to find the best model\n",
    "# tpot = TPOTRegressor(generations=10, population_size=50, verbosity=2, random_state=41)\n",
    "\n",
    "# # track time in hours and minutes\n",
    "# start_time = time.time()\n",
    "\n",
    "# tpot.fit(X_train, y_train)\n",
    "\n",
    "# # Print the time elapsed\n",
    "# print_time_taken(start_time, time.time())\n",
    "\n",
    "# print(tpot.score(X_test, y_test))\n",
    "# tpot.export('tpot_exported_pipeline.py')\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# predictions = tpot.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the model\n",
    "# test_model(tpot, X_test, y_test, predictions)\n",
    "\n",
    "# # Plot the predictions against the actual values\n",
    "# plot_predicted_vs_actual(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TPOT result\n",
    "# from sklearn.svm import LinearSVR\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from tpot.builtins import StackingEstimator\n",
    "# from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "# # Average CV score on the training set was: -0.6345471715614988\n",
    "# exported_pipeline = make_pipeline(\n",
    "#     StackingEstimator(estimator=LinearSVR(C=20.0, dual=True, epsilon=0.01, loss=\"epsilon_insensitive\", tol=0.01)),\n",
    "#     DecisionTreeRegressor(max_depth=8, min_samples_leaf=16, min_samples_split=12)\n",
    "# )\n",
    "# # Fix random state for all the steps in exported pipeline\n",
    "# set_param_recursive(exported_pipeline.steps, 'random_state', 41)\n",
    "\n",
    "# # track time in hours and minutes\n",
    "# start_time = time.time()\n",
    "\n",
    "# exported_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Print the time elapsed\n",
    "# print_time_taken(start_time, time.time())\n",
    "\n",
    "# predictions = exported_pipeline.predict(X_test)\n",
    "\n",
    "# test_model(exported_pipeline, X_test, y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_model, ridge_model, lasso_model, elastic_net_model\n",
    "if(train_model and (linear_model or ridge_model or lasso_model or elastic_net_model)):\n",
    "    model_type = None\n",
    "\n",
    "    # track time in hours and minutes\n",
    "    start_time = time.time()\n",
    "\n",
    "    if(linear_model):\n",
    "        # Create the linear regression model and train/fit it\n",
    "        print('linear model is training...')\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        model_type = 'linear_regression'\n",
    "    elif(ridge_model):\n",
    "        # Create the ridge regression model and train/fit it, use GridSearchCV to find the best alpha\n",
    "        print('ridge model is training...')\n",
    "        model = Ridge()\n",
    "        parameters = {'alpha': [1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001]}\n",
    "        ridge_regressor = GridSearchCV(model, parameters, n_jobs=3)\n",
    "        ridge_regressor.fit(X_train, y_train)\n",
    "        print(ridge_regressor.best_params_)\n",
    "        model = ridge_regressor.best_estimator_\n",
    "        model_type = 'ridge_regression'\n",
    "    elif(lasso_model):\n",
    "        # Create the lasso regression model and train/fit it, use GridSearchCV to find the best alpha\n",
    "        print('lasso model is training...')\n",
    "        model = Lasso(max_iter=5000)\n",
    "        parameters = {'alpha': [1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001]}\n",
    "        lasso_regressor = GridSearchCV(model, parameters, n_jobs=3)\n",
    "        lasso_regressor.fit(X_train, y_train)\n",
    "        print(lasso_regressor.best_params_)\n",
    "        model = lasso_regressor.best_estimator_\n",
    "        model_type = 'lasso_regression'\n",
    "    elif(elastic_net_model):\n",
    "        # Create the elastic net regression model and train/fit it, use GridSearchCV to find the best alpha and l1_ratio\n",
    "        print('elastic net model is training...')\n",
    "        model = ElasticNet(max_iter=5000)\n",
    "        parameters = {'alpha': [1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001], 'l1_ratio': [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 0.9]}\n",
    "        elastic_net_regressor = GridSearchCV(model, parameters, n_jobs=3)\n",
    "        elastic_net_regressor.fit(X_train, y_train)\n",
    "        print(elastic_net_regressor.best_params_)\n",
    "        model = elastic_net_regressor.best_estimator_\n",
    "        model_type = 'elastic_net_regression'\n",
    "    \n",
    "    \n",
    "    # Print the time elapsed\n",
    "    print_time_taken(start_time, time.time())\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Test the model\n",
    "    test_model(model, X_test, y_test, predictions)\n",
    "\n",
    "    # Plot the predictions against the actual values\n",
    "    plot_predicted_vs_actual(y_test, predictions)\n",
    "\n",
    "    # save model to folder models\\linear_regression with a timestamp in the name\n",
    "    filename = f'models/linear_regression/model_{model_type}_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.pkl'\n",
    "    save_to_pickle_file(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso model hyperparams are tuned...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307b7c23790b4c3ebab5391020418aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 00:10:29\n",
      "Best values: [0.999719393901264, 0.28657524786746685, 0.999719393901264] | best params: {'alpha': 0.00023449032674716}\n"
     ]
    }
   ],
   "source": [
    "def optuna_linear_train_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and evaluate the model\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    # return accuracy\n",
    "    return accuracy, mse, r2\n",
    "\n",
    "# linear models optuna\n",
    "if train_model and linear_optuna_model :\n",
    "    ridge_model_optuna = False\n",
    "    lasso_model_optuna = True\n",
    "    elastic_net_model_optuna = False   \n",
    "    # show minimal output\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "    # Ridge\n",
    "    if ridge_model_optuna or lasso_model_optuna:\n",
    "    # random forest with optuna\n",
    "        if ridge_model_optuna:\n",
    "            print('ridge model hyperparams are tuned...')\n",
    "        else:\n",
    "            print('lasso model hyperparams are tuned...')\n",
    "\n",
    "        def objective(trial):\n",
    "            # suggest hyperparameters alpha 1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001\n",
    "            alpha = trial.suggest_float('alpha', 0.0001, 1)\n",
    "            \n",
    "            # Create and train the Random Forest model\n",
    "            if ridge_model_optuna:\n",
    "                model = Ridge(alpha=alpha, random_state=41)\n",
    "            elif lasso_model_optuna:\n",
    "                model = Lasso(alpha=alpha, max_iter=5000, random_state=41)\n",
    "            \n",
    "            # return optuna_linear_train_evaluate(model, X_train, y_train, X_test, y_test)\n",
    "            return optuna_linear_train_evaluate(model, X_train, y_train, X_test_specific, y_test_specific)\n",
    "    elif elastic_net_model_optuna:\n",
    "        print('elastic net model hyperparams are tuned...')\n",
    "        def objective(trial):\n",
    "            # suggest hyperparameters alpha 1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001\n",
    "            alpha = trial.suggest_float('alpha', 0.0001, 1)\n",
    "            l1_ratio = trial.suggest_float('l1_ratio', 0.01, 1)\n",
    "            \n",
    "            # Create and train the Random Forest model\n",
    "            model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, max_iter=5000, random_state=41)\n",
    "\n",
    "            # return optuna_linear_train_evaluate(model, X_train, y_train, X_test, y_test)\n",
    "            return optuna_linear_train_evaluate(model, X_train, y_train, X_test_specific, y_test_specific)\n",
    "            \n",
    "    # Initialize Optuna study\n",
    "    study = optuna.create_study(directions=[\"maximize\", \"minimize\", \"maximize\"])\n",
    "    \n",
    "    # Track time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Optimize the study\n",
    "    study.optimize(objective, n_trials=10000, n_jobs=-1, show_progress_bar=True)  # Adjust n_trials for your needs\n",
    "    \n",
    "    # Print time taken\n",
    "    print_time_taken(start_time, time.time())\n",
    "    \n",
    "    # Print the best parameters\n",
    "    for best_trial in study.best_trials:\n",
    "        print(f\"Best values: {best_trial.values} | best params: {best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial linear regression\n",
    "if(train_model and polynomial_model):   \n",
    "    polynomial_degrees = [2, 3, 4]\n",
    "    accuracy_score_highest = 0\n",
    "    best_predictions = None\n",
    "    best_model = None\n",
    "\n",
    "    # track time in hours and minutes\n",
    "    start_time = time.time()\n",
    "\n",
    "    for degree in polynomial_degrees:\n",
    "        print(\"Polynomial degree: \", degree)\n",
    "\n",
    "        # Create the linear regression model and train/fit it\n",
    "        model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        # Calculate the metrics of the model\n",
    "        accuracy_initial = model.score(X_test, y_test)\n",
    "        accuracy = round(accuracy_initial * 100, 2)\n",
    "        print(f\"Accuracy: {accuracy}%\")\n",
    "\n",
    "        # Calculate the mean squared error of the model\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        print(f\"Mean squared error: {mse}\")\n",
    "\n",
    "        # Calculate the R-Squared score of the model\n",
    "        print('Variance (R²) score: %.2f' % r2_score(y_test, predictions))\n",
    "        \n",
    "        # save model to folder models\\linear_regression with a timestamp in the name\n",
    "        filename = f'models/linear_regression/model_poly_{degree}_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.pkl'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "        if (accuracy_initial > accuracy_score_highest):\n",
    "            accuracy_score_highest = accuracy_initial\n",
    "            best_predictions = predictions\n",
    "            best_model = model\n",
    "\n",
    "    # Print the time elapsed\n",
    "    print_time_taken(start_time, time.time())\n",
    "\n",
    "    model = best_model\n",
    "\n",
    "    # Plot the predictions against the actual values\n",
    "    plot_predicted_vs_actual(y_test, best_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random forest with for-loop\n",
    "# if(train_model and random_forest_model):\n",
    "#     accuracy_score_highest = 0\n",
    "#     best_predictions = None\n",
    "#     best_model = None\n",
    "    \n",
    "#     for n_estimators in range(1, 11):\n",
    "#         for max_depth in range(1, 51):\n",
    "#     # for n_estimators in [38, 39, 40, 49, 50, 51]:\n",
    "#     # for max_depth in [9, 10, 11, 30, 31, 32]:\n",
    "#             # print(f\"---- n_estimators: {n_estimators}\")\n",
    "#             print(f\"---- n_estimators: {n_estimators} - max_depth: {max_depth}\")\n",
    "            \n",
    "#             # Create the random forest model and train/fit it\n",
    "#             # model = RandomForestRegressor(n_estimators=n_estimators, random_state=41, n_jobs=-1)\n",
    "#             model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth , random_state=41, n_jobs=-1)\n",
    "\n",
    "#             start = time.time()\n",
    "#             model.fit(X_train, y_train)\n",
    "#             print_time_taken(start, time.time())\n",
    "            \n",
    "#             # Make predictions on the test set\n",
    "#             predictions = model.predict(X_test)\n",
    "\n",
    "#             accuracy = model.score(X_test, y_test)\n",
    "#             accuracy_score = round(accuracy * 100, 2)\n",
    "#             mean_squared_error_test = mean_squared_error(y_test, predictions)\n",
    "#             r2_score_test = r2_score(y_test, predictions)\n",
    "\n",
    "#             # # Make predictions on the test set\n",
    "#             # predictions = model.predict(X_test_specific)\n",
    "\n",
    "#             # accuracy = model.score(X_test_specific, y_test_specific)\n",
    "#             # accuracy_score = round(accuracy * 100, 2)\n",
    "#             # mean_squared_error_test = mean_squared_error(y_test_specific, predictions)\n",
    "#             # r2_score_test = r2_score(y_test_specific, predictions)\n",
    "\n",
    "#             # filename = f'models/random_forest/model_rf_{n_estimators}.pkl'\n",
    "#             filename = f'models/random_forest/model_rf_{n_estimators}_{max_depth}.pkl'\n",
    "#             save_to_pickle_file(model, filename)\n",
    "\n",
    "#             if (accuracy > accuracy_score_highest):\n",
    "#                 accuracy_score_highest = accuracy\n",
    "                \n",
    "#                 # get accuracy of the model\n",
    "#                 print(\"Accuracy of the model: \", accuracy_score, \"%\")\n",
    "\n",
    "#                 # test the model\n",
    "#                 print(\"Mean squared error: %.2f\" % mean_squared_error_test)\n",
    "#                 print('Variance (R²) score: %.2f' % r2_score_test)\n",
    "\n",
    "#                 # # remove evertyhing in folder models\\random_forest that starts with model_\n",
    "#                 # import os, glob\n",
    "#                 # files = glob.glob('models/random_forest/model_*')\n",
    "#                 # for f in files:\n",
    "#                 #     os.remove(f)\n",
    "\n",
    "#                 # save model to folder models\\random_forest with a timestamp in the name\n",
    "#                 # filename = f'models/random_forest/model_rf_{n_estimators}.pkl'\n",
    "#                 # filename = f'models/random_forest/model_rf_{n_estimators}_{max_depth}.pkl'\n",
    "#                 save_to_pickle_file(model, filename)\n",
    "\n",
    "#                 best_predictions = predictions\n",
    "#                 best_model = model\n",
    "\n",
    "#     model = best_model\n",
    "\n",
    "#     # Plot the predictions against the actual values\n",
    "#     # plot_predicted_vs_actual(y_test, predictions)\n",
    "#     plot_predicted_vs_actual(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest with GridSearchCV\n",
    "if train_model and random_forest_model:\n",
    "    best_predictions = None\n",
    "    best_model = None\n",
    "\n",
    "    # # Define the parameter grid for GridSearchCV\n",
    "    # param_grid = {\n",
    "    #     'n_estimators': range(1, 101)\n",
    "    # }\n",
    "       \n",
    "    param_grid = {\n",
    "        'n_estimators': range(1, 51),\n",
    "        'max_depth': range(1, 51)\n",
    "    }\n",
    "\n",
    "    # Create the Random Forest model\n",
    "    model = RandomForestRegressor(random_state=41)\n",
    "\n",
    "    # Perform Grid Search to find the best hyperparameters\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='r2', cv=5, n_jobs=-1, verbose=3)\n",
    "\n",
    "    # track time in hours and minutes\n",
    "    start_time = time.time()\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the time elapsed\n",
    "    print_time_taken(start_time, time.time())\n",
    "\n",
    "    # Get the best model and its parameters\n",
    "    model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Make predictions on the test set using the best model\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the best model\n",
    "    accuracy_score = model.score(X_test, y_test) * 100\n",
    "    mean_squared_error_test = mean_squared_error(y_test, predictions)\n",
    "    r2_score_test = r2_score(y_test, predictions)\n",
    "\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print(\"Accuracy of the best model: {:.2f}%\".format(accuracy_score))\n",
    "    print(\"Mean squared error: {:.2f}\".format(mean_squared_error_test))\n",
    "    print(\"Variance (R²) score: {:.2f}\".format(r2_score_test))\n",
    "\n",
    "    # Save the model\n",
    "\n",
    "    filename = 'models/random_forest/best_model_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.pkl'\n",
    "    save_to_pickle_file(model, filename)\n",
    "\n",
    "    # Plot the predictions against the actual values\n",
    "    plot_predicted_vs_actual(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random forest with optuna\n",
    "# if train_model and random_forest_model:\n",
    "#     # show minimal output\n",
    "#     optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "#     # random forest with optuna\n",
    "#     def objective(trial):\n",
    "#         # Suggest hyperparameters\n",
    "#         n_estimators = trial.suggest_int('n_estimators', 1, 50)\n",
    "#         max_depth = trial.suggest_int('max_depth', 1, 50)\n",
    "        \n",
    "#         # Create and train the Random Forest model\n",
    "#         model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=41)\n",
    "#         model.fit(X_train, y_train)\n",
    "        \n",
    "#         # Make predictions and evaluate the model\n",
    "#         predictions = model.predict(X_test)\n",
    "        \n",
    "#         accuracy = model.score(X_test, y_test)\n",
    "#         mse = mean_squared_error(y_test, predictions)\n",
    "#         r2 = r2_score(y_test, predictions)\n",
    "        \n",
    "#         # return accuracy\n",
    "#         return accuracy, mse, r2\n",
    "    \n",
    "#     # Initialize Optuna study\n",
    "#     study = optuna.create_study(directions=[\"maximize\", \"minimize\", \"maximize\"])\n",
    "    \n",
    "#     # Track time\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     # Optimize the study\n",
    "#     study.optimize(objective, n_trials=10000, n_jobs=-1, show_progress_bar=True)  # Adjust n_trials for your needs\n",
    "    \n",
    "#     # Print time taken\n",
    "#     print_time_taken(start_time, time.time())\n",
    "    \n",
    "#     # Print the best parameters\n",
    "#     for best_trial in study.best_trials:\n",
    "#         print(f\"Best values: {best_trial.values} | best params: {best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------- END MODEL TRAINING --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(train_model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m random_forest_model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m polynomial_model):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Plot the prediction power of the features that model is using, in a horizontal bar chart\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m     plt\u001b[38;5;241m.\u001b[39mbarh(features, \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcoef_)\n\u001b[0;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCoefficient\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatures\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the prediction power of the features that model is using, in a horizontal bar chart\n",
    "if(train_model and not random_forest_model and not polynomial_model):\n",
    "    # Plot the prediction power of the features that model is using, in a horizontal bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(features, model.coef_)\n",
    "    plt.xlabel('Coefficient')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title('Feature coefficients')\n",
    "    plt.show()\n",
    "elif(train_model and random_forest_model):\n",
    "    # Plot the prediction power of the features that the random forest regression model is using, in a horizontal bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(features, model.feature_importances_)\n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title('Feature importance')\n",
    "    plt.show()\n",
    "elif(train_model and polynomial_model):\n",
    "    # Plot the prediction power of the features that the polynomial regression model is using, in a horizontal bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(features, model.named_steps['linearregression'].coef_)\n",
    "    plt.xlabel('Coefficient')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title('Feature coefficients')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fetch test data for prediction\n",
    "# # give me a record in merged_df where percentage current is 100, give me the first one\n",
    "# data_100 = merged_df[merged_df['percentage_current'] == 100].iloc[0]\n",
    "\n",
    "# # give me a record in merged_df where percentage current is between 45 and 55, give me the first one\n",
    "# # merged_df[(merged_df['percentage_current'] >= 45) & (merged_df['percentage_current'] <= 55)].iloc[0]\n",
    "\n",
    "# print(data_100)\n",
    "# # data_100 = data_100.reindex(['date'] + list(data_100.index[:-1]))\n",
    "# # data_100 = data_100.drop('timestamp')\n",
    "# # data_100 = data_100.drop('percentage_current')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test prediction\n",
    "# if(train_model):\n",
    "#     # prediction_1 = model.predict(scale_features([[6, 2, 2024, 1, 8, 0, 3.4, 0]]))\n",
    "#     # prediction_2 = model.predict(scale_features([[6, 2, 2024, 1, 8, 0, 3.4, 10]]))\n",
    "#     # prediction_3 = model.predict(scale_features([[6, 2, 2024, 1, 8, 0, 3.4, 0]]))\n",
    "#     # 'day', 'month', 'dayofweek', 'hour', 'rainfall_current', 'rainfall_previous_2_hours', 'percentage_previous_1', 'percentage_previous_2', 'percentage_previous_3',\n",
    "#     # 'percentage_previous_4', 'percentage_previous_5', 'percentage_previous_6'\n",
    "#     # rainfall_previous_array = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "#     date_features_array = [28, 1, 0, 2]\n",
    "#     rainfall_features = [0.139999, 2.299995]\n",
    "#     rainfall_previous_feature_array = [0, 0, 0, 0, 0, 0]\n",
    "#     percentage_previous_feature_array = [96.4912, 95.614, 95.614, 95.614, 94.737, 93.86]\n",
    "#     percentage_difference_feature_array = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "#     input = pd.DataFrame([date_features_array + rainfall_features + percentage_previous_feature_array + rainfall_previous_feature_array], columns=features)\n",
    "#     # input = pd.DataFrame([data_100], columns=features)\n",
    "\n",
    "#     prediction_4 = model.predict(scale_features(input))\n",
    "\n",
    "#     # print(prediction_1)\n",
    "#     # print(prediction_2)\n",
    "#     # print(prediction_3)\n",
    "#     print(prediction_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather data shift 6 months later\n",
    "# set every timestamp in merged_df to 6 months later, and put this in a new dataframe\n",
    "weather_data_6_months_later = merged_df.copy()\n",
    "weather_data_6_months_later['timestamp'] = weather_data_6_months_later['timestamp'] + pd.DateOffset(months=6)\n",
    "# only give me timestamp and rainfall_current\n",
    "weather_data_6_months_later = weather_data_6_months_later[['timestamp', 'rainfall_current', 'rainfall_previous_2_hours']]\n",
    "weather_data_6_months_later\n",
    "\n",
    "# # export weather_data_6_months_later to xlsx\n",
    "# weather_data_6_months_later.to_excel('data/cleaned_data/weather_data_6_months_later.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prediction(prediction):\n",
    "    if(prediction < 0):\n",
    "        return  0\n",
    "    elif(prediction > 100):\n",
    "        return  100\n",
    "    else:\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_verbose = False\n",
    "predictions_to_excel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_input(dataset, percentages_previous, start_timestamp):\n",
    "# def data_to_input(dataset, percentages_previous, percentage_difference, start_timestamp):\n",
    "    # print('---------------- TIMESTAMP ----------------', start_timestamp)\n",
    "    data_specific_timestamp = dataset[dataset['timestamp'] == start_timestamp]\n",
    "    data_specific_timestamp = convert_timestamp_to_numerical(data_specific_timestamp)\n",
    "    \n",
    "    # print(data_specific_timestamp)\n",
    "    day = data_specific_timestamp['day'].values[0]\n",
    "    month = data_specific_timestamp['month'].values[0]\n",
    "    dayofweek = data_specific_timestamp['dayofweek'].values[0]\n",
    "    hour = data_specific_timestamp['hour'].values[0]\n",
    "    # date = data_specific_timestamp['date'].values[0]\n",
    "    date_features = [day, month, dayofweek, hour]\n",
    "\n",
    "    rainfall_current = data_specific_timestamp[\"rainfall_current\"].values[0]\n",
    "    rainfall_previous_2_hours = data_specific_timestamp['rainfall_previous_2_hours'].values[0]\n",
    "   \n",
    "    percentage_previous_1 = percentages_previous[0]\n",
    "    percentage_previous_2 = percentages_previous[1]\n",
    "    percentage_previous_3 = percentages_previous[2]\n",
    "    percentage_previous_4 = percentages_previous[3]\n",
    "    percentage_previous_5 = percentages_previous[4]\n",
    "    percentage_previous_6 = percentages_previous[5]\n",
    "    percentage_previous_array = [percentage_previous_1, percentage_previous_2, percentage_previous_3, percentage_previous_4, percentage_previous_5, percentage_previous_6]\n",
    "\n",
    "    # percentage_difference_1 = percentage_difference[0]\n",
    "    # percentage_difference_2 = percentage_difference[1]\n",
    "    # percentage_difference_3 = percentage_difference[2]\n",
    "    # percentage_difference_4 = percentage_difference[3]\n",
    "    # percentage_difference_5 = percentage_difference[4]\n",
    "    # percentage_difference_6 = percentage_difference[5]\n",
    "    # percentage_difference_7 = percentage_difference[6]\n",
    "    # percentage_difference_8 = percentage_difference[7]\n",
    "    # percentage_difference_9 = percentage_difference[8]\n",
    "    # percentage_difference_10 = percentage_difference[9]\n",
    "    # percentage_difference_11 = percentage_difference[10]\n",
    "    # percentage_difference_12 = percentage_difference[11]\n",
    "    # percentage_differences_array = [percentage_difference_1, percentage_difference_2, percentage_difference_3, percentage_difference_4, percentage_difference_5, percentage_difference_6, percentage_difference_7, percentage_difference_8, percentage_difference_9, percentage_difference_10, percentage_difference_11, percentage_difference_12]\n",
    " \n",
    "    input_df = pd.DataFrame([date_features + [rainfall_current, rainfall_previous_2_hours] + percentage_previous_array], columns=features)\n",
    "\n",
    "    if training_verbose:\n",
    "        print('----INPUT_DF----\\n', input_df.values)\n",
    "    \n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_predictions_df(start_timestamp, weather_data, model, scaler, polygon_id, range_previous_percentage):\n",
    "    initial_timestamps_minus = []\n",
    "    initial_previous_percentage = [0] * range_previous_percentage\n",
    "    initial_differences_percentage = [0] * 12\n",
    "    pre_predictions_df = None\n",
    "    \n",
    "    for i in range(1, range_previous_percentage+1):\n",
    "        start_timestamp_minus = start_timestamp - pd.Timedelta(minutes=i*5)\n",
    "        initial_timestamps_minus.append(start_timestamp_minus)\n",
    "    \n",
    "    # turn around initial_timestamps_minus\n",
    "    initial_timestamps_minus.reverse()\n",
    "    \n",
    "    if training_verbose:\n",
    "        print('------ PRE-PREDICTION DATES-------\\n', initial_timestamps_minus)\n",
    "\n",
    "    for start_timestamp_minus in initial_timestamps_minus:\n",
    "        if training_verbose:\n",
    "            print('------ CURRENT PRE-PREDICTION DATE:', start_timestamp_minus)\n",
    "            \n",
    "        weather_data_minus = convert_timestamp_to_numerical(weather_data[weather_data['timestamp'] == start_timestamp_minus])\n",
    "        \n",
    "        input_minus = data_to_input(weather_data_minus, initial_previous_percentage, start_timestamp_minus)\n",
    "        # input_minus = data_to_input(weather_data_minus, initial_previous_percentage, initial_differences_percentage, start_timestamp_minus)\n",
    "        # print('------input_minus-------', input_minus.filter(regex='percentage_previous_'))\n",
    "\n",
    "        prediction_minus = format_prediction(model.predict(scaler.transform(input_minus))[0])\n",
    "\n",
    "        if training_verbose:\n",
    "            print('------CURRENT PRE-PREDICTION RESULT:', prediction_minus)\n",
    "\n",
    "        # add prediction_minus to the front of initial_previous_percentage\n",
    "        initial_previous_percentage.insert(0, prediction_minus)\n",
    "        initial_previous_percentage.pop()\n",
    "\n",
    "        # # add value to pre_percentage_differences and remove last value\n",
    "        # initial_differences_percentage.insert(0, prediction_minus - initial_previous_percentage[1])\n",
    "        # initial_differences_percentage.pop()\n",
    "\n",
    "        # add record to pre_predictions_df\n",
    "        pre_predictions_df = pd.concat([pre_predictions_df, pd.DataFrame([[start_timestamp_minus, prediction_minus, input_minus['rainfall_current'].values[0]]], columns=['timestamp', 'percentage_current', 'rainfall_current'])], ignore_index=True)\n",
    "\n",
    "    return initial_previous_percentage, initial_differences_percentage, pre_predictions_df\n",
    "\n",
    "def create_predictions_df(start_timestamp, end_timestamp, weather_data, model, scaler, polygon_id):\n",
    "    if training_verbose:\n",
    "        print('------------------------------------ PRE-PREDICTIONS ------------------------------------')   \n",
    "    \n",
    "    # Make the initial predictions (start_timestamp, weather_data, model, scaler, polygon_id, range_previous_percentage (per 5 minutes back))\n",
    "    pre_percentage_predictions, pre_percentage_differences, pre_predictions_df = create_initial_predictions_df(start_timestamp, weather_data, model, scaler, polygon_id, 6)\n",
    "    \n",
    "    if training_verbose:\n",
    "        print('------------------------------------ PREDICTIONS ------------------------------------')   \n",
    "    \n",
    "    # Create a boolean mask for the specified time range\n",
    "    mask = (weather_data['timestamp'] >= start_timestamp) & (weather_data['timestamp'] <= end_timestamp)\n",
    "\n",
    "    # Apply the mask to get the desired slice of the DataFrame\n",
    "    weather_data = weather_data[mask]\n",
    "\n",
    "    # initialize predictions_df\n",
    "    predictions_df = None\n",
    "    # predictions_df = pd.DataFrame(columns=['timestamp', 'percentage_current', 'rainfall_current'])\n",
    "    \n",
    "    print('Pre-predictions:\\n', pre_predictions_df)\n",
    "\n",
    "    while(start_timestamp <= end_timestamp):\n",
    "        # convert multiple data sources to one input\n",
    "        input_prediction = data_to_input(weather_data, pre_percentage_predictions, start_timestamp)\n",
    "        # input_prediction = data_to_input(weather_data, pre_percentage_predictions, pre_percentage_differences, start_timestamp)\n",
    "\n",
    "        # scale and predict\n",
    "        prediction = model.predict(scaler.transform(input_prediction))\n",
    "        prediction = format_prediction(prediction[0])\n",
    "        \n",
    "        # add record to predictions_df, use concat\n",
    "        predictions_df = pd.concat([predictions_df, pd.DataFrame([[start_timestamp, prediction, input_prediction['rainfall_current'].values[0]]], columns=['timestamp', 'percentage_current', 'rainfall_current'])], ignore_index=True)\n",
    "\n",
    "        # add value to pre_predictions and remove last value\n",
    "        pre_percentage_predictions.insert(0, prediction)\n",
    "        pre_percentage_predictions.pop()\n",
    "\n",
    "        # # add value to pre_percentage_differences and remove last value\n",
    "        # pre_percentage_differences.insert(0, prediction - pre_percentage_predictions[1])\n",
    "        # pre_percentage_differences.pop()\n",
    "\n",
    "        # increment start_timestamp with 5 minutes\n",
    "        start_timestamp = start_timestamp + pd.Timedelta(minutes=5)\n",
    "\n",
    "    return predictions_df, pre_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_and_rainfall(pred_df, pre_pred_df, model_name):\n",
    "    # plot the predictions in a line chart, put the percentage and rainfull_current against each other\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    ax1.set_xlabel('Timestamp')\n",
    "    ax1.set_ylabel('Rainfall (mm)')\n",
    "    ax1.plot(pred_df['timestamp'], pred_df['rainfall_current'], color='blue')\n",
    "    ax1.plot(pre_pred_df['timestamp'], pre_pred_df['rainfall_current'], color='blue', linestyle='dashed')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Percentage (%)')\n",
    "    ax2.plot(pred_df['timestamp'], pred_df['percentage_current'], color='red')\n",
    "    ax2.plot(pre_pred_df['timestamp'], pre_pred_df['percentage_current'], color='red', linestyle='dashed')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    fig.legend(['Rainfall', 'Rainfall pre', 'Percentage', 'Percentage pre'], loc='upper right')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.title(f'Rainfall and percentage full over time - {model_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_and_actual(pred_df, pre_pred_df, model_name, actual_data):\n",
    "    # plot the predictions and actual data in a line chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.set_xlabel('Timestamp')\n",
    "    ax.set_ylabel('Percentage (%)')\n",
    "    ax.plot(actual_data['timestamp'], actual_data['percentage_current'], color='blue')\n",
    "    ax.plot(pred_df['timestamp'], pred_df['percentage_current'], color='red')\n",
    "    ax.plot(pre_pred_df['timestamp'], pre_pred_df['percentage_current'], color='red', linestyle='dashed')\n",
    "\n",
    "    fig.legend(['Actual data', 'Prediction', 'Prediction pre'], loc='upper right')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.title(f'Predicted percentage full over time - {model_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_plot(model, scaler, model_name, start_timestamp, end_timestamp, future_weather_data, polygon_id, against_actual):\n",
    "    print(f'------------------------------------ {model_name} ------------------------------------')\n",
    "\n",
    "    # Make the predictions\n",
    "    pred_df, pre_pred_df = create_predictions_df(start_timestamp, end_timestamp, future_weather_data, model, scaler, polygon_id)\n",
    "\n",
    "    # # Test the model\n",
    "    # print('\\nMetrics for full test set:')\n",
    "    # predictions = model.predict(X_test)\n",
    "    # test_model(model, X_test, y_test, predictions)\n",
    "\n",
    "    # Test the model on the specific test set\n",
    "    print('\\nMetrics for this specific prediction:')\n",
    "    predictions = model.predict(X_test_specific)\n",
    "    test_model(model, X_test_specific, y_test_specific, predictions)\n",
    "    \n",
    "    if(against_actual):\n",
    "        # Plot the predictions against the actual values\n",
    "        plot_predictions_and_actual(pred_df, pre_pred_df, model_name, future_weather_data)\n",
    "    else:\n",
    "        # Plot the predictions against the rainfall\n",
    "        plot_predictions_and_rainfall(pred_df, pre_pred_df, model_name)\n",
    "\n",
    "    if(predictions_to_excel):\n",
    "        # write pred_df to excel in folder predictions, with a timestamp in the name and model name in the name (linear_regression)\n",
    "        pred_df.to_excel(f'predictions/pred_df_{model_name}_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.xlsx', index=False)\n",
    "        pre_pred_df.to_excel(f'predictions/pre_pred_df_{model_name}_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "plot_against_actual = True\n",
    "\n",
    "# if not train model\n",
    "if not train_model:\n",
    "    print('[[----- BEST MODELS ARE LOADED -----]]')\n",
    "    # load all models from folder models\\best_models, put them in a dictionary with the file name as key\n",
    "    models = {}\n",
    "    # files = glob.glob('models/best_models/model_*')\n",
    "    files_linear_shuffled = glob.glob('models/best_models/fixed_data/linear_shuffled/model_*')\n",
    "    # files_linear_shuffled_stf = glob.glob('models/best_models/fixed_data/linear_shuffled_stf/model_*')\n",
    "    # files_randomforest_shuffled = glob.glob('models/best_models/fixed_data/random_forest_shuffled/model_*')\n",
    "    # files_randomforest_shuffled_stf = glob.glob('models/best_models/fixed_data/random_forest_shuffled_stf/model_*')\n",
    "\n",
    "    # files_linear_shuffled = glob.glob('models/best_models/old_data/linear_shuffled/model_*')\n",
    "    # files_randomforest_shuffled = glob.glob('models/best_models/old_data/random_forest_shuffled/model_*')\n",
    "    # files_randomforest_shuffled_stf = glob.glob('models/best_models/old_data/random_forest_shuffled_stf/model_*')\n",
    "\n",
    "\n",
    "    # files_linear = glob.glob('models/best_models/linear/model_*')\n",
    "    # files_randomforest = glob.glob('models/best_models/random_forest/model_*')\n",
    "\n",
    "    # files = files_linear + files_randomforest + files_linear_shuffled + files_randomforest_shuffled\n",
    "    files =  files_linear_shuffled\n",
    "\n",
    "    # Load the scaler from folder models\\best_models\n",
    "    scaler_path = glob.glob('models/best_models/scaler_*')\n",
    "    scaler = pickle.load(open(scaler_path[0], 'rb'))\n",
    "\n",
    "    for f in files:\n",
    "        # model name is everything after model_ and before .pkl\n",
    "        model_name = f.split('model_')[1].split('.pkl')[0]\n",
    "        models[model_name] = pickle.load(open(f, 'rb'))\n",
    "\n",
    "        # # save model with the same name\n",
    "        # filename = f'models/best_models/random_forest_shuffled/model_{model_name}.pkl'\n",
    "        # save_to_pickle_file(models[model_name], filename)\n",
    "\n",
    "        weather_data_for_loaded_models = None\n",
    "\n",
    "        if(plot_against_actual):\n",
    "            weather_data_for_loaded_models = merged_df[(merged_df['timestamp'] >= start_timestamp_for_testing - pd.Timedelta(minutes=30)) & (merged_df['timestamp'] <= end_timestamp_for_testing)].copy()\n",
    "        else:\n",
    "            weather_data_for_loaded_models = weather_data_6_months_later\n",
    "\n",
    "        predict_test_plot(models[model_name], scaler, model_name, start_timestamp_for_testing, end_timestamp_for_testing, weather_data_for_loaded_models, 'polygon_1663', plot_against_actual)\n",
    "else:\n",
    "    print('[[----- NEW MODEL USED -----]]')\n",
    "\n",
    "    pred_df, pre_pred_df = create_predictions_df(start_timestamp_for_testing, end_timestamp_for_testing, weather_data_6_months_later, model, scaler, 'polygon_1663')\n",
    "\n",
    "    plot_predictions_and_rainfall(pred_df, pre_pred_df, 'new model')\n",
    "\n",
    "    if(predictions_to_excel):\n",
    "        # write pred_df to excel in folder predictions\n",
    "        pred_df.to_excel('predictions/pred_df_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.xlsx', index=False)\n",
    "        pre_pred_df.to_excel('predictions/pre_pred_df_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fullenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
