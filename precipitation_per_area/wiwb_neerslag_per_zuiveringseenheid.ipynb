{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {},
      "source": [
        "import pyspark.sql.functions as F\r\n",
        "from datetime import datetime, timedelta, date\r\n",
        "from pyspark.sql.types import TimestampType\r\n",
        "from pyspark.sql.functions import sum, to_date, col, when, month, dayofmonth, explode, array, struct, expr, lit , avg\r\n",
        "import geopandas as gpd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from shapely import wkt\r\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Load dataframes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "%run Meta/connection_information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#create mount point\r\n",
        "mssparkutils.fs.mount( \r\n",
        "    ADLS_PATH+\"/base/extern/wiwb/\", \r\n",
        "    \"/bwiwb/\", \r\n",
        "    {\"linkedService\":\"AzureDataLakeStorage1\"} \r\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#load geojson polygon file\r\n",
        "cells = gpd.read_file(f\"/synfs/{mssparkutils.env.getJobId()}/bwiwb/polygons_irc.geojson\")\r\n",
        "cells.index = cells[\"index\"]\r\n",
        "cells = cells.drop(columns=['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#load dataframes\r\n",
        "BASE_GIS_FOLDER = '/base/wsbd/gis/WEB_Beheerregister_Afvalwaterketen/zuiveringseenheden'\r\n",
        "BASE_IRC_FOLDER = '/base/extern/wiwb/irc_combined'\r\n",
        "ENRICHED_FOLDER = '/enriched/extern/waterketen'\r\n",
        "\r\n",
        "# Needed to check when pipeline was last succesfull\r\n",
        "data_source = 'neerslag_per_zuivering'\r\n",
        "# Get today's date\r\n",
        "today_date = date.today()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def get_max_date_value(data_source: str) -> int:\r\n",
        "    try:\r\n",
        "        # Get the maximum timestamp value from the specified column\r\n",
        "        max_timestamp = spark.read.format('delta').load(f'{ENRICHED_FOLDER}/{data_source}').select(F.max(F.col(\"date_hour\"))).first()[0]\r\n",
        "        # Convert the maximum timestamp to a datetime object\r\n",
        "        max_datetime = datetime.strptime(str(max_timestamp), '%Y-%m-%d %H')\r\n",
        "        # Calculate the difference in days between max date and today\r\n",
        "        date_difference = (today_date - max_datetime.date()).days\r\n",
        "    except:\r\n",
        "        return 0\r\n",
        "    return date_difference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# filter data based last date in the source file\r\n",
        "date_difference = get_max_date_value(data_source)\r\n",
        "days_ago = today_date - timedelta(days=date_difference)\r\n",
        "\r\n",
        "year, month, day = days_ago.year, days_ago.month, days_ago.day\r\n",
        "DATE_FROM = date(year, month, day)\r\n",
        "\r\n",
        "# load irc to DataFrame\r\n",
        "df_irc = spark.read \\\r\n",
        "            .format('delta') \\\r\n",
        "            .load(BASE_IRC_FOLDER)\r\n",
        "\r\n",
        "df_irc = df_irc.filter((df_irc.timestamp >= DATE_FROM))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Zet coordinaat systeem van de polygon geosjson om van rd new naar wgs84**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Create a GeoDataFrame from the Pandas DataFrame\r\n",
        "cells = gpd.GeoDataFrame(cells, geometry=\"geometry\")\r\n",
        "\r\n",
        "# Define the RD New and WGS84 CRS\r\n",
        "crs_rd = \"EPSG:28992\"\r\n",
        "crs_wgs84 = \"EPSG:4326\"\r\n",
        "\r\n",
        "# Set the CRS of the original GeoDataFrame to RD New\r\n",
        "cells.crs = crs_rd\r\n",
        "\r\n",
        "# Convert the coordinates to WGS84 using .to_crs()\r\n",
        "cells_84 = cells.to_crs(crs_wgs84)\r\n",
        "\r\n",
        "# Plot the geometries using GeoPandas\r\n",
        "#cells.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Laad gislaag in**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# load zuiveringseenheden to DataFrame\r\n",
        "zuiveringseenheden_df = (\r\n",
        "    spark\r\n",
        "    .read\r\n",
        "    .format(\"delta\")\r\n",
        "    .load(BASE_GIS_FOLDER))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Convert the Spark DataFrame to a Pandas DataFrame\r\n",
        "zuiveringseenheden_df_pandas = zuiveringseenheden_df.toPandas()\r\n",
        "\r\n",
        "# Convert the WKT geometries to Shapely geometries\r\n",
        "zuiveringseenheden_df_pandas[\"geometry\"] = gpd.GeoSeries.from_wkt(zuiveringseenheden_df_pandas[\"geometrie\"])\r\n",
        "zuiveringseenheden_df_pandas = zuiveringseenheden_df_pandas.drop(columns=['geometrie'])\r\n",
        "\r\n",
        "# Create a GeoDataFrame from the Pandas DataFrame\r\n",
        "gpd_zuiveringseenheden = gpd.GeoDataFrame(zuiveringseenheden_df_pandas, geometry=\"geometry\", crs=\"EPSG:4326\")\r\n",
        "\r\n",
        "# Plot the geometries using GeoPandas\r\n",
        "#zuiveringseenheden_df.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# # Create a new plot\r\n",
        "# fig, ax = plt.subplots()\r\n",
        "\r\n",
        "# # Plot the geometries from the first GeoDataFrame\r\n",
        "# cells_84.plot(ax=ax, color='blue', label='raster cellen WIWB')\r\n",
        "\r\n",
        "# # Plot the geometries from the second GeoDataFrame\r\n",
        "# gpd_zuiveringseenheden.plot(ax=ax, color='red', label='Zuiveringseenheden')\r\n",
        "\r\n",
        "# # Set plot title and legend\r\n",
        "# plt.title(\"Polygon laag ten opzichte van zuiveringseenhedn\")\r\n",
        "# plt.legend()\r\n",
        "\r\n",
        "# # Show the plot\r\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Make an intersection of the zuiveringseenheden and the polygonen and use the selected polygons to select the right data from the wiwb dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Reset the index\r\n",
        "cells_84 = cells_84.reset_index()\r\n",
        "\r\n",
        "# Perform the spatial join using 'union' as the operation in overlay\r\n",
        "union_gdf = cells_84.overlay(gpd_zuiveringseenheden, how='union')\r\n",
        "\r\n",
        "union_gdf['area'] = union_gdf.area\r\n",
        "\r\n",
        "# Drop rows with NaN values in the specified column\r\n",
        "union_gdf = union_gdf.dropna(subset=['index','naam'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Calculate percentage of surface that belongs to the zuivering\r\n",
        "# Multiply the 'area' column by 10000 and round the percentage column\r\n",
        "union_gdf['percentage'] = (union_gdf['area'] * 10000 / 0.011895).round(0)\r\n",
        "\r\n",
        "# Drop geometry and area\r\n",
        "union_gdf = union_gdf.drop(columns=['geometry','area','naam'])\r\n",
        "\r\n",
        "# Convert Pandas DataFrame to PySpark DataFrame\r\n",
        "union_spark = spark.createDataFrame(union_gdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# resample the data to daily data, summing the precipitation\r\n",
        "df_irc = df_irc.groupBy(to_date('timestamp').alias('date'))\\\r\n",
        "                .sum()\r\n",
        "\r\n",
        "# adjust col names to match dict\r\n",
        "remove_sum_col_names = list(map(lambda x: x.replace(\"sum(\", \"\").replace(\")\", \"\"), df_irc.columns[1:]))\r\n",
        "df_irc = df_irc.toDF(\"date\", *remove_sum_col_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#function to melt dataframe\r\n",
        "def to_explode(df, by):\r\n",
        "\r\n",
        "    # Filter dtypes and split into column names and type description\r\n",
        "    cols, dtypes = zip(*((c, t) for (c, t) in df.dtypes if c not in by))\r\n",
        "    # Spark SQL supports only homogeneous columns\r\n",
        "    assert len(set(dtypes)) == 1, \"All columns have to be of the same type\"\r\n",
        "\r\n",
        "    # Create and explode an array of (column_name, column_value) structs\r\n",
        "    kvs = explode(array([\r\n",
        "      struct(lit(c).alias(\"polygon\"), col(c).alias(\"precipation\")) for c in cols\r\n",
        "    ])).alias(\"kvs\")\r\n",
        "\r\n",
        "    return df.select(by + [kvs]).select(by + [\"kvs.polygon\", \"kvs.precipation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "columns_to_drop = ['year', 'month', 'day']\r\n",
        "df_irc = df_irc.drop(*columns_to_drop)\r\n",
        "\r\n",
        "#start function\r\n",
        "df_irc_explode = to_explode(df_irc, ['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#join irc and percentage zuiveringseenheid\r\n",
        "df_irc_total = df_irc_explode.join(union_spark,df_irc_explode.polygon ==  union_spark.index,\"fullouter\")\r\n",
        "\r\n",
        "# Drop rows where \"index\" is null\r\n",
        "df_irc_total = df_irc_total.filter(col(\"index\").isNotNull())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#percentage surface * amount of precipation\r\n",
        "df_irc_total = df_irc_total\\\r\n",
        "  .withColumn('precipitation_percentage', (F.col('percentage')*F.col('precipation'))/100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#aggregate zuivering days and precipitation\r\n",
        "zuiveringen_precipitation = df_irc_total.groupby(\"date\",\"CODE\")\\\r\n",
        "    .agg(avg(\"precipitation_percentage\").cast('double').alias(\"precipitation\"),\\\r\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# save DataFrame\r\n",
        "zuiveringen_precipitation.write \\\r\n",
        "        .format(\"delta\") \\\r\n",
        "        .mode(\"append\") \\\r\n",
        "        .save(f'{ENRICHED_FOLDER}/neerslag_per_zuivering')\r\n",
        ""
      ]
    }
  ]
}